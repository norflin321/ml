{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([4, 8, 2])\n",
      "---- b: 0\n",
      "-- t: 0, cur_and_prev: torch.Size([1, 2]), mean: tensor([ 0.1808, -0.0700])\n",
      "-- t: 1, cur_and_prev: torch.Size([2, 2]), mean: tensor([-0.0894, -0.4926])\n",
      "-- t: 2, cur_and_prev: torch.Size([3, 2]), mean: tensor([ 0.1490, -0.3199])\n",
      "-- t: 3, cur_and_prev: torch.Size([4, 2]), mean: tensor([ 0.3504, -0.2238])\n",
      "-- t: 4, cur_and_prev: torch.Size([5, 2]), mean: tensor([0.3525, 0.0545])\n",
      "-- t: 5, cur_and_prev: torch.Size([6, 2]), mean: tensor([ 0.0688, -0.0396])\n",
      "-- t: 6, cur_and_prev: torch.Size([7, 2]), mean: tensor([ 0.0927, -0.0682])\n",
      "-- t: 7, cur_and_prev: torch.Size([8, 2]), mean: tensor([-0.0341,  0.1332])\n",
      "---- b: 1\n",
      "-- t: 0, cur_and_prev: torch.Size([1, 2]), mean: tensor([ 1.3488, -0.1396])\n",
      "-- t: 1, cur_and_prev: torch.Size([2, 2]), mean: tensor([0.8173, 0.4127])\n",
      "-- t: 2, cur_and_prev: torch.Size([3, 2]), mean: tensor([-0.1342,  0.4395])\n",
      "-- t: 3, cur_and_prev: torch.Size([4, 2]), mean: tensor([0.2711, 0.4774])\n",
      "-- t: 4, cur_and_prev: torch.Size([5, 2]), mean: tensor([0.2421, 0.0694])\n",
      "-- t: 5, cur_and_prev: torch.Size([6, 2]), mean: tensor([0.0084, 0.0020])\n",
      "-- t: 6, cur_and_prev: torch.Size([7, 2]), mean: tensor([ 0.0712, -0.1128])\n",
      "-- t: 7, cur_and_prev: torch.Size([8, 2]), mean: tensor([0.2527, 0.2149])\n",
      "---- b: 2\n",
      "-- t: 0, cur_and_prev: torch.Size([1, 2]), mean: tensor([-0.6631, -0.2513])\n",
      "-- t: 1, cur_and_prev: torch.Size([2, 2]), mean: tensor([ 0.1735, -0.0649])\n",
      "-- t: 2, cur_and_prev: torch.Size([3, 2]), mean: tensor([0.1685, 0.3348])\n",
      "-- t: 3, cur_and_prev: torch.Size([4, 2]), mean: tensor([-0.1621,  0.1765])\n",
      "-- t: 4, cur_and_prev: torch.Size([5, 2]), mean: tensor([-0.2312, -0.0436])\n",
      "-- t: 5, cur_and_prev: torch.Size([6, 2]), mean: tensor([-0.1015, -0.2855])\n",
      "-- t: 6, cur_and_prev: torch.Size([7, 2]), mean: tensor([-0.2593, -0.1630])\n",
      "-- t: 7, cur_and_prev: torch.Size([8, 2]), mean: tensor([-0.3015, -0.2293])\n",
      "---- b: 3\n",
      "-- t: 0, cur_and_prev: torch.Size([1, 2]), mean: tensor([ 1.6455, -0.8030])\n",
      "-- t: 1, cur_and_prev: torch.Size([2, 2]), mean: tensor([ 1.4985, -0.5395])\n",
      "-- t: 2, cur_and_prev: torch.Size([3, 2]), mean: tensor([0.4954, 0.3420])\n",
      "-- t: 3, cur_and_prev: torch.Size([4, 2]), mean: tensor([ 1.0623, -0.1802])\n",
      "-- t: 4, cur_and_prev: torch.Size([5, 2]), mean: tensor([ 1.1401, -0.4462])\n",
      "-- t: 5, cur_and_prev: torch.Size([6, 2]), mean: tensor([ 1.0870, -0.4071])\n",
      "-- t: 6, cur_and_prev: torch.Size([7, 2]), mean: tensor([ 1.0430, -0.1299])\n",
      "-- t: 7, cur_and_prev: torch.Size([8, 2]), mean: tensor([ 1.1138, -0.1641])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398],\n",
      "        [-0.9211,  1.5433]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# A mathematical trick that is used in the self attention inside a transformer\n",
    "# and at the heart of an efficient implementation of self-attention\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "print(\"x:\", x.shape)\n",
    "\n",
    "# Now we would like this 8 tokens in a batch to talk to each other. But the token for example at the fifth location\n",
    "# should not communicate with future tokens in a sequence (6, 7, 8, ...). It should only talk to tokens in (4, 3, 2, ...) locations.\n",
    "# So information only flows from previous context to the current timestamp and we cannot get any information from the future\n",
    "# because we are about to try to predict the future.\n",
    "# The easiest way for tokens to communicate is to just do an average of all the preceding elements.\n",
    "# For example if i am the fifth token (T) i would like to take channels (C) that make up information at my step but\n",
    "# then also the channels from the four, third, second and first steps. I'd like to average those up and then that would\n",
    "# become sort of like a feature vector that summarizes me in the context of my history.\n",
    "\n",
    "# for each T inside each B, we wanna calculate the average of current T and all the previous\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "  print(\"---- b:\", b)\n",
    "  for t in range(T):\n",
    "    cur_and_prev = x[b, :t+1]\n",
    "    mean = torch.mean(cur_and_prev, 0)\n",
    "    xbow[b,t] = mean\n",
    "    print(f\"-- t: {t}, cur_and_prev: {cur_and_prev.shape}, mean: {mean}\")\n",
    "\n",
    "print(xbow[0])\n",
    "print(x[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# short version using: tril, softmax, matrix mul.\n",
    "\n",
    "wei = torch.zeros((T,T))\n",
    "print(wei)\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "print(wei)\n",
    "wei = F.softmax(wei, dim=1) # normalization to 1\n",
    "print(wei)\n",
    "xbow2 = wei @ x\n",
    "print(torch.allclose(xbow, xbow2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
