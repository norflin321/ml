{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/norflin321/ml/blob/main/SDXL_sketch2img.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUc62icy4CfA"
      },
      "outputs": [],
      "source": [
        "%pip install -U git+https://github.com/huggingface/diffusers.git controlnet_aux==0.0.7 > install_logs.txt\n",
        "%pip install transformers accelerate safetensors mediapipe invisible_watermark > install_logs.txt\n",
        "\n",
        "from diffusers import StableDiffusionXLAdapterPipeline, T2IAdapter, EulerAncestralDiscreteScheduler, AutoencoderKL, StableDiffusionInstructPix2PixPipeline, StableDiffusionXLImg2ImgPipeline\n",
        "from diffusers.utils import load_image, make_image_grid\n",
        "from controlnet_aux.pidi import PidiNetDetector\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load euler_a scheduler\n",
        "euler_a = EulerAncestralDiscreteScheduler.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", subfolder=\"scheduler\")\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "pidinet = PidiNetDetector.from_pretrained(\"lllyasviel/Annotators\").to(\"cuda\")\n",
        "\n",
        "# load adapter\n",
        "adapter = T2IAdapter.from_pretrained(\"TencentARC/t2i-adapter-sketch-sdxl-1.0\", torch_dtype=torch.float16, varient=\"fp16\").to(\"cuda\")\n",
        "\n",
        "# load model\n",
        "# https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/adapter#diffusers.StableDiffusionXLAdapterPipeline\n",
        "# https://huggingface.co/docs/diffusers/v0.21.0/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pretrained\n",
        "pipe = StableDiffusionXLAdapterPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", vae=vae, adapter=adapter, scheduler=euler_a, torch_dtype=torch.float16, variant=\"fp16\")\n",
        "pipe.to(\"cuda\")\n",
        "pipe.load_lora_weights(\"./finetuned\", weight_name=\"pytorch_lora_weights.safetensors\")\n",
        "# pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "# refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16)\n",
        "# refiner.to(\"cuda\")\n",
        "# generator = torch.Generator(\"cuda\").manual_seed(42)\n",
        "\n",
        "# prepare sketch image\n",
        "# url = \"https://i.imgur.com/HE1TYkx.png\"\n",
        "url = \"https://i.imgur.com/m92Alz2.png\"\n",
        "image = load_image(url)\n",
        "image = pidinet(image, detect_resolution=1024, image_resolution=1024, apply_filter=True)"
      ],
      "metadata": {
        "id": "r1dFvwFPKTuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HYPERPARAMS\n",
        "prompt = \"a magic creature in style of sks, 3D, blender, perfect, 4k graphics, highly detailed, cute, pretty\"\n",
        "negative_prompt = \"extra digit, fewer digits, cropped, worst quality, low quality, glitch, deformed, mutated, ugly, disfigured\"\n",
        "steps = 50\n",
        "guidance = 8\n",
        "adapter_conditioning_scale = 0.9\n",
        "seed = None\n",
        "\n",
        "# generate\n",
        "current_seed = seed or torch.randint(0, int(1e5), size=(1, 1))[0].item()\n",
        "generator = torch.Generator().manual_seed(int(current_seed))\n",
        "img = pipe(prompt=prompt, negative_prompt=negative_prompt, image=image, num_inference_steps=steps, adapter_conditioning_scale=adapter_conditioning_scale, guidance_scale=guidance, generator=generator).images[0]\n",
        "# img = refiner(prompt=prompt, generator=generator, image=img).images[0]\n",
        "time_now = datetime.datetime.now().strftime(\"%y.%m.%d_%H:%M:%S\")\n",
        "img.save(f\"./{time_now}_{current_seed}.png\")\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "print(\"seed:\", current_seed)"
      ],
      "metadata": {
        "id": "EGj6a-3Uc5jn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}