{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3zg1GM/yAD4WpT0Fy2e3Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/norflin321/ml/blob/main/SDXL_txt2img.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ-OmiGyU2Ut"
      },
      "outputs": [],
      "source": [
        "%pip install -U git+https://github.com/huggingface/diffusers.git controlnet_aux==0.0.7 > install_logs.txt\n",
        "%pip install transformers accelerate safetensors mediapipe invisible_watermark > install_logs.txt\n",
        "\n",
        "from diffusers import StableDiffusionXLAdapterPipeline, T2IAdapter, EulerAncestralDiscreteScheduler, AutoencoderKL, StableDiffusionInstructPix2PixPipeline, StableDiffusionXLImg2ImgPipeline, StableDiffusionXLPipeline\n",
        "from diffusers.utils import load_image, make_image_grid\n",
        "from controlnet_aux.pidi import PidiNetDetector\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load euler_a scheduler\n",
        "euler_a = EulerAncestralDiscreteScheduler.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", subfolder=\"scheduler\")\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "pidinet = PidiNetDetector.from_pretrained(\"lllyasviel/Annotators\").to(\"cuda\")\n",
        "\n",
        "# load SDXL model\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", vae=vae, scheduler=euler_a, torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
        "\n",
        "# load finetuned weights\n",
        "pipe.load_lora_weights(\"./finetuned\", weight_name=\"pytorch_lora_weights.safetensors\")"
      ],
      "metadata": {
        "id": "UO8oC1VGU4cH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HYPERPARAMS\n",
        "prompt = \"photo of sks\"\n",
        "negative_prompt = \"\"\n",
        "steps = 50\n",
        "guidance = 8\n",
        "adapter_conditioning_scale = 0.9\n",
        "seed = None\n",
        "\n",
        "# generate\n",
        "current_seed = seed or torch.randint(0, int(1e5), size=(1, 1))[0].item()\n",
        "generator = torch.Generator().manual_seed(int(current_seed))\n",
        "img = pipe(prompt=prompt, negative_prompt=negative_prompt, num_inference_steps=steps, guidance_scale=guidance, generator=generator).images[0]\n",
        "time_now = datetime.datetime.now().strftime(\"%y.%m.%d_%H:%M:%S\")\n",
        "img.save(f\"./{time_now}_{current_seed}.png\")\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "print(\"seed:\", current_seed)"
      ],
      "metadata": {
        "id": "NvtFT0PfU5gv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}